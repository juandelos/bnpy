{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Visualizing learned state sequences and transition probabilities\n\nTrain a sticky HDP-HMM model on small motion capture data, then visualize the MAP state sequences under the estimated model parameters by running Viterbi.\n\nAlso has some info on how to inspect the learned HMM parameters of a sticky HDP-HMM model trained on small motion capture data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 3\n\nimport bnpy\nimport numpy as np\nimport os\n\nimport matplotlib\nfrom matplotlib import pylab\nimport seaborn as sns\n\nnp.set_printoptions(suppress=1, precision=3)\n\nFIG_SIZE = (10, 5)\npylab.rcParams['figure.figsize'] = FIG_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load dataset from file\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_path = os.path.join(bnpy.DATASET_PATH, 'mocap6')\ndataset = bnpy.data.GroupXData.read_npz(\n    os.path.join(dataset_path, 'dataset.npz'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Function to make a simple plot of the raw data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def show_single_sequence(\n        seq_id,\n        zhat_T=None,\n        z_img_cmap=None,\n        ylim=[-120, 120],\n        K=5,\n        left=0.2, bottom=0.2, right=0.8, top=0.95):\n    if z_img_cmap is None:\n        z_img_cmap = matplotlib.cm.get_cmap('Set1', K)\n\n    if zhat_T is None:\n        nrows = 1\n    else:\n        nrows = 2\n    fig_h, ax_handles = pylab.subplots(\n        nrows=nrows, ncols=1, sharex=True, sharey=False)\n    ax_handles = np.atleast_1d(ax_handles).flatten().tolist()\n\n    start = dataset.doc_range[seq_id]\n    stop = dataset.doc_range[seq_id + 1]\n    # Extract current sequence\n    # as a 2D array : T x D (n_timesteps x n_dims)\n    curX_TD = dataset.X[start:stop]\n    for dim in range(12):\n        ax_handles[0].plot(curX_TD[:, dim], '.-')\n    ax_handles[0].set_ylabel('angle')\n    ax_handles[0].set_ylim(ylim)\n    z_img_height = int(np.ceil(ylim[1] - ylim[0]))\n    pylab.subplots_adjust(\n        wspace=0.1,\n        hspace=0.1,\n        left=left, right=right,\n        bottom=bottom, top=top)\n    if zhat_T is not None:\n        img_TD = np.tile(zhat_T, (z_img_height, 1))\n        ax_handles[1].imshow(\n            img_TD,\n            interpolation='nearest',\n            vmin=-0.5, vmax=(K-1)+0.5,\n            cmap=z_img_cmap)\n        ax_handles[1].set_ylim(0, z_img_height)\n        ax_handles[1].set_yticks([])\n\n        bbox = ax_handles[1].get_position()\n        width = (1.0 - bbox.x1) / 3\n        height = bbox.y1 - bbox.y0\n        cax = fig_h.add_axes([right + 0.01, bottom, width, height])\n        cbax_h = fig_h.colorbar(\n            ax_handles[1].images[0], cax=cax, orientation='vertical')\n        cbax_h.set_ticks(np.arange(K))\n        cbax_h.set_ticklabels(np.arange(K))\n        cbax_h.ax.tick_params(labelsize=9)\n\n    ax_handles[-1].set_xlabel('time')\n    return ax_handles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization of the first sequence (1 of 6)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "show_single_sequence(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: hyperparameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "K = 5            # Number of clusters/states\n\n# Allocation model (HDP)\ngamma      =   5.0  # top-level Dirichlet concentration parameter\ntransAlpha =   0.5  # trans-level Dirichlet concentration parameter \nstartAlpha =  10.0  # starting-state Dirichlet concentration parameter\nhmmKappa   =  50.0  # set sticky self-transition weight\n\n# Observation model (1st-order Auto-regressive Gaussian)\nsF = 1.0          # Set observation model prior so E[covariance] = identity\nECovMat = 'eye'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train HDP-HMM with *AutoRegGauss* observation model\n\nTrain single model for all 6 sequences.\n\nDo small number of clusters jut to make visualization easy.\n\nTake the best of 5 random initializations (in terms of evidence lower bound).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hdphmm_trained_model, hmmar_info_dict = bnpy.run(\n    dataset, 'HDPHMM', 'AutoRegGauss', 'memoVB',\n    output_path=(\n        '/tmp/mocap6/showcase-K=%d-model=HDPHMM+AutoRegGauss-ECovMat=1*eye/'\n        % (K)),\n    nLap=100, nTask=5, nBatch=1, convergeThr=0.0001,\n    transAlpha=transAlpha, startAlpha=startAlpha, hmmKappa=hmmKappa,\n    gamma=gamma,\n    sF=sF, ECovMat=ECovMat,\n    K=K, initname='randexamples',\n    printEvery=25,\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the starting-state probabilities\n\nstart_prob_K : 1D array, size K\n    start_prob_K[k] = exp( E[log Pr(start state = k)] )\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "start_prob_K = hdphmm_trained_model.allocModel.get_init_prob_vector()\n\nprint(start_prob_K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the transition probabilities\n\ntrans_prob_KK : 2D array, K x K\n    trans_prob_KK[j, k] = exp( E[log Pr(z_t = k | z_t-1 = j)] )\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trans_prob_KK = hdphmm_trained_model.allocModel.get_trans_prob_matrix()\n\nprint(trans_prob_KK)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute log likelihood of each timestep for sequence 0\n\nlog_lik_TK : 2D array, T x K\n    log_lik_TK[t, k] = E[ log Pr( observed data at time t | z_t = k)]\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "log_lik_seq0_TK = hdphmm_trained_model.obsModel.calcLogSoftEvMatrix_FromPost(\n    dataset.make_subset([0])\n    )\n\nprint(log_lik_seq0_TK[:10, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Viterbi algorithm for sequence 0\n\nzhat_T : 1D array, size T\n    MAP state sequence\n    zhat_T[t] = state assigned to timestep t, will be int value in {0, 1, ... K-1}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "zhat_seq0_T = bnpy.allocmodel.hmm.HMMUtil.runViterbiAlg(\n    log_lik_seq0_TK, np.log(start_prob_K), np.log(trans_prob_KK))\n\nprint(zhat_seq0_T[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the segmentation for sequence 0\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "show_single_sequence(0, zhat_T=zhat_seq0_T, K=K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the segmentation for sequence 1\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "log_lik_seq1_TK = hdphmm_trained_model.obsModel.calcLogSoftEvMatrix_FromPost(\n    dataset.make_subset([1])\n    )\nzhat_seq1_T = bnpy.allocmodel.hmm.HMMUtil.runViterbiAlg(\n    log_lik_seq1_TK, np.log(start_prob_K), np.log(trans_prob_KK))\n\nshow_single_sequence(1, zhat_T=zhat_seq1_T, K=K)\n\n\npylab.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}