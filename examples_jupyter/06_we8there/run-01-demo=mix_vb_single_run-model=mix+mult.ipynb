{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# VB coordinate descent for Mixture of Multinomials\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import bnpy\nimport numpy as np\nimport os\n\nfrom matplotlib import pylab\nimport seaborn as sns\n\nFIG_SIZE = (3, 3)\nSMALL_FIG_SIZE = (1,1)\npylab.rcParams['figure.figsize'] = FIG_SIZE\n\ntop_word_kws = dict(\n    wordSizeLimit=15,\n    ncols=4,\n    Ktop=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read text dataset from file\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_path = os.path.join(bnpy.DATASET_PATH, 'we8there', 'raw')\ndataset = bnpy.data.BagOfWordsData.read_npz(\n    os.path.join(dataset_path, 'dataset.npz'),\n    vocabfile=os.path.join(dataset_path, 'x_csc_colnames.txt'))\n\n# Filter out documents with less than 20 words\ndoc_ids = np.flatnonzero(\n    dataset.getDocTypeCountMatrix().sum(axis=1) >= 20)\ndataset = dataset.make_subset(docMask=doc_ids, doTrackFullSize=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make a simple plot of the raw data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bnpy.viz.PrintTopics.plotCompsFromWordCounts(\n    dataset.getDocTypeCountMatrix()[:10],\n    vocabList=dataset.vocabList,\n    prefix='doc',\n    **top_word_kws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train with K=1 cluster\n\nThis is a simple baseline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trained_model, info_dict = bnpy.run(\n    dataset, 'DPMixtureModel', 'Mult', 'VB',\n    output_path='/tmp/we8there/helloworld-model=dp_mix+mult-K=1/',\n    nLap=1000, convergeThr=0.0001, nTask=1,\n    K=1, initname='bregmankmeans+lam1+iter1',\n    gamma0=50.0, lam=0.1)\n\nbnpy.viz.PrintTopics.plotCompsFromHModel(\n    trained_model,\n    vocabList=dataset.vocabList,\n    **top_word_kws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train with K=3 clusters\n\nTake the best of 10 initializations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trained_model, info_dict = bnpy.run(\n    dataset, 'DPMixtureModel', 'Mult', 'VB',\n    output_path='/tmp/we8there/helloworld-model=dp_mix+mult-K=3/',\n    nLap=1000, convergeThr=0.0001, nTask=10,\n    K=3, initname='bregmankmeans+lam1+iter1',\n    gamma0=50.0, lam=0.1)\n\nbnpy.viz.PrintTopics.plotCompsFromHModel(\n    trained_model,\n    vocabList=dataset.vocabList,\n    **top_word_kws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train with K=10 clusters\n\nTake the best of 10 initializations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trained_model, info_dict = bnpy.run(\n    dataset, 'DPMixtureModel', 'Mult', 'VB',\n    output_path='/tmp/we8there/helloworld-model=dp_mix+mult-K=10/',\n    nLap=1000, convergeThr=0.0001, nTask=10,\n    K=10, initname='bregmankmeans+lam1+iter1',\n    gamma0=50.0, lam=0.1)\n\nbnpy.viz.PrintTopics.plotCompsFromHModel(\n    trained_model,\n    vocabList=dataset.vocabList,\n    **top_word_kws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train with K=30 clusters\n\nTake the best of 10 initializations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trained_model, info_dict = bnpy.run(\n    dataset, 'DPMixtureModel', 'Mult', 'VB',\n    output_path='/tmp/we8there/helloworld-model=dp_mix+mult-K=30/',\n    nLap=1000, convergeThr=0.0001, nTask=10,\n    K=30, initname='bregmankmeans+lam1+iter1',\n    gamma0=50.0, lam=0.1)\n\nbnpy.viz.PrintTopics.plotCompsFromHModel(\n    trained_model,\n    vocabList=dataset.vocabList,\n    **top_word_kws)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}