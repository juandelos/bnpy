{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Birth and merge variational training for topic model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import bnpy\nimport numpy as np\nimport os\n\nfrom matplotlib import pylab\nimport seaborn as sns\n\nFIG_SIZE = (2, 2)\nSMALL_FIG_SIZE = (1.5, 1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read text dataset from file\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_path = os.path.join(bnpy.DATASET_PATH, 'we8there', 'raw')\ndataset = bnpy.data.BagOfWordsData.read_npz(\n    os.path.join(dataset_path, 'dataset.npz'),\n    vocabfile=os.path.join(dataset_path, 'x_csc_colnames.txt'))\n\n# Filter out documents with less than 20 words\ndoc_ids = np.flatnonzero(\n    dataset.getDocTypeCountMatrix().sum(axis=1) >= 20)\ndataset = dataset.make_subset(docMask=doc_ids, doTrackFullSize=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train LDA topic model\n\nUsing 10 clusters and a random initialization procedure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "local_step_kwargs = dict(\n    # perform at most this many iterations at each document\n    nCoordAscentItersLP=100,\n    # stop local iters early when max change in doc-topic counts < this thr\n    convThrLP=0.001,\n    )\nmerge_kwargs = dict(\n    m_startLap=5,\n    )\nbirth_kwargs = dict(\n    b_startLap=2,\n    b_stopLap=20,\n    b_Kfresh=5)\n\ntrained_model, info_dict = bnpy.run(\n    dataset, 'HDPTopicModel', 'Mult', 'memoVB',\n    output_path='/tmp/we8there/trymoves-model=hdp_topic+mult-K=5/',\n    nLap=20, convergeThr=0.01, nBatch=1,\n    K=5, initname='randomlikewang',\n    gamma=50.0, alpha=0.5, lam=0.1,\n    moves='birth,merge,shuffle',\n    **dict(list(local_step_kwargs.items()) + \n        list(merge_kwargs.items()) + \n        list(birth_kwargs.items())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup: Helper function to plot topics at each stage of training\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def show_top_words_over_time(\n        task_output_path=None,\n        vocabList=None,\n        query_laps=[0, 1, 2, 5, None],\n        ncols=10):\n    '''\n    '''\n    nrows = len(query_laps)\n    fig_handle, ax_handles_RC = pylab.subplots(\n        figsize=(SMALL_FIG_SIZE[0] * ncols, SMALL_FIG_SIZE[1] * nrows),\n        nrows=nrows, ncols=ncols, sharex=True, sharey=True)\n    for row_id, lap_val in enumerate(query_laps):\n        cur_model, lap_val = bnpy.load_model_at_lap(task_output_path, lap_val)\n        # Plot the current model\n        cur_ax_list = ax_handles_RC[row_id].flatten().tolist()\n        bnpy.viz.PrintTopics.plotCompsFromHModel(\n            cur_model,\n            vocabList=vocabList,\n            fontsize=9,\n            Ktop=7,\n            ax_list=cur_ax_list)\n        cur_ax_list[0].set_ylabel(\"lap: %d\" % lap_val)\n    pylab.subplots_adjust(\n        wspace=0.04, hspace=0.1, \n        left=0.01, right=0.99, top=0.99, bottom=0.1)\n    pylab.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the topics over time\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "show_top_words_over_time(\n    info_dict['task_output_path'], vocabList=dataset.vocabList)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}