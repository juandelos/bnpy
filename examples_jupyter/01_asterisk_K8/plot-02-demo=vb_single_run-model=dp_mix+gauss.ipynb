{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Variational coordinate descent for Mixture of Gaussians\n",
        "\n",
        "How to do Variational Bayes (VB) coordinate descent for GMM.\n",
        "\n",
        "Here, we train a finite mixture of Gaussians with full covariances.\n",
        "\n",
        "We'll consider a mixture model with a symmetric Dirichlet prior:\n",
        "\n",
        "\\begin{align}\\pi \\sim \\mbox{Dir}(1/K, 1/K, \\ldots 1/K)\\end{align}\n",
        "\n",
        "as well as a standard conjugate prior on the mean and covariances, such that\n",
        "\n",
        "\\begin{align}\\E[\\mu_k] = 0\n",
        "\n",
        "    \\E[\\Sigma_k] = 0.1 I_D\\end{align}\n",
        "\n",
        "We will initialize the approximate variational posterior \n",
        "using K=10 randomly chosen examples ('randexamples' procedure),\n",
        "and then perform coordinate descent updates\n",
        "(alternating local step and global step) until convergence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# SPECIFY WHICH PLOT CREATED BY THIS SCRIPT IS THE THUMBNAIL IMAGE\n",
        "# sphinx_gallery_thumbnail_number = 3\n",
        "\n",
        "import bnpy\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from matplotlib import pylab\n",
        "import seaborn as sns\n",
        "\n",
        "FIG_SIZE = (3, 3)\n",
        "pylab.rcParams['figure.figsize'] = FIG_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read bnpy's built-in \"AsteriskK8\" dataset from file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_path = os.path.join(bnpy.DATASET_PATH, 'AsteriskK8')\n",
        "dataset = bnpy.data.XData.read_npz(\n",
        "    os.path.join(dataset_path, 'x_dataset.npz'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make a simple plot of the raw data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pylab.plot(dataset.X[:, 0], dataset.X[:, 1], 'k.')\n",
        "pylab.gca().set_xlim([-2, 2])\n",
        "pylab.gca().set_ylim([-2, 2])\n",
        "pylab.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the model\n",
        "Let's do one single run of the VB algorithm.\n",
        "\n",
        "Using 10 clusters and the 'randexamples' initializatio procedure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trained_model, info_dict = bnpy.run(\n",
        "    dataset, 'FiniteMixtureModel', 'Gauss', 'VB',\n",
        "    output_path='/tmp/AsteriskK8/helloworld-K=10/',\n",
        "    nLap=100,\n",
        "    sF=0.1, ECovMat='eye',\n",
        "    K=10,\n",
        "    initname='randexamples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss function trace plot\n",
        "We can plot the value of the loss function over iterations,\n",
        "starting after the first full pass over the dataset (first lap).\n",
        "\n",
        "As expected, we see monotonic decrease in the loss function's score \n",
        "after every subsequent iteration.\n",
        "\n",
        "Remember that the VB algorithm for GMMs is *guaranteed*\n",
        "to decrease this loss function after every step.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pylab.plot(info_dict['lap_history'][1:], info_dict['loss_history'][1:], 'k.-')\n",
        "pylab.xlabel('num. laps')\n",
        "pylab.ylabel('loss')\n",
        "pylab.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization of learned clusters\n",
        "Here's a short function to show the learned clusters over time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def show_clusters_over_time(\n",
        "        task_output_path=None,\n",
        "        query_laps=[0, 1, 2, 5, 10, None],\n",
        "        nrows=2):\n",
        "    ''' Read model snapshots from provided folder and make visualizations\n",
        "\n",
        "    Post Condition\n",
        "    --------------\n",
        "    New matplotlib plot with some nice pictures.\n",
        "    '''\n",
        "    ncols = int(np.ceil(len(query_laps) // float(nrows)))\n",
        "    fig_handle, ax_handle_list = pylab.subplots(\n",
        "        figsize=(FIG_SIZE[0] * ncols, FIG_SIZE[1] * nrows),\n",
        "        nrows=nrows, ncols=ncols, sharex=True, sharey=True)\n",
        "    for plot_id, lap_val in enumerate(query_laps):\n",
        "        cur_model, lap_val = bnpy.load_model_at_lap(task_output_path, lap_val)\n",
        "        # Plot the current model\n",
        "        cur_ax_handle = ax_handle_list.flatten()[plot_id]\n",
        "        bnpy.viz.PlotComps.plotCompsFromHModel(\n",
        "            cur_model, Data=dataset, ax_handle=cur_ax_handle)\n",
        "        cur_ax_handle.set_xticks([-2, -1, 0, 1, 2])\n",
        "        cur_ax_handle.set_yticks([-2, -1, 0, 1, 2])\n",
        "        cur_ax_handle.set_xlabel(\"lap: %d\" % lap_val)\n",
        "    pylab.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the estimated clusters over time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "show_clusters_over_time(info_dict['task_output_path'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
